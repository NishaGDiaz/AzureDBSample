{"cells":[{"cell_type":"code","source":["# Set up Account Access Key\n# spark.conf.set(\n#  \"fs.azure.account.key.<storage-account-name>.blob.core.windows.net\",\n#  \"<storage-access-key>\")\n\nspark.conf.set(\n  \"fs.azure.account.key.dbblobstore.blob.core.windows.net\",\n  \"VHiGGTYmDtROgk+821m0fHqowvikN5WTQtK51KQQz/ME9dokZCrvVjYpCnT7WgYF1o6Xm+4RIu+Omhz1bzTF2Q==\")"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#Access files in your container as if they were local files\n#dbutils.fs.ls(\"wasbs://<your-container-name>@<your-storage-account-name>.blob.core.windows.net/<your-directory-name>\")\ndbutils.fs.ls(\"wasbs://dbdemo01@dbblobstore.blob.core.windows.net\")"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["# Mount a Blob storage container or a folder inside a container\n# dbutils.fs.mount(\n#   source = \"wasbs://<your-container-name>@<your-storage-account-name>.blob.core.windows.net/<your-directory-name>\",\n#   mount_point = \"<mount-point-path>\",\n#   extra_configs = <\"<conf-key>\": \"<conf-value>\">)\n# [note] <mount_point> is a DBFS path and the path must be under /mnt\n\ndbutils.fs.mount(\n  source = \"wasbs://dbdemo01@dbblobstore.blob.core.windows.net\",\n  mount_point = \"/mnt/dbdemo01\",\n  extra_configs = {\"fs.azure.account.key.dbblobstore.blob.core.windows.net\": \"VHiGGTYmDtROgk+821m0fHqowvikN5WTQtK51KQQz/ME9dokZCrvVjYpCnT7WgYF1o6Xm+4RIu+Omhz1bzTF2Q==\"})"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["dbutils.fs.ls(\"/mnt/dbdemo01\")"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["# Access files in your container as if they were local files\n# (TEXT) df = spark.read.text(\"/mnt/%s/....\" % <mount-point-path>)\n# (JSON) df = spark.read.json(\"/mnt/%s/....\" % <mount-point-path>)\n\ndf = spark.read.json( \"/mnt/%s/small_radio_json.json\" % \"dbdemo01\")\n\n# display(df)\ndf.show()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["specificColumnsDf = df.select(\"firstname\", \"lastname\", \"gender\", \"location\", \"level\")\nspecificColumnsDf.show()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["renamedColumnsDF = specificColumnsDf.withColumnRenamed(\"level\", \"subscription_type\")\nrenamedColumnsDF.show()"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["#Load data into Azure Cosmos DB\n#writeConfig = {\n# \"Endpoint\" : \"https://<cosmosdb-account-name>.documents.azure.com:443/\",\n# \"Masterkey\" : \"<Cosmosdb-master-key-string>\",\n# \"Database\" : \"<database-name>\",\n# \"Collection\" : \"<collection-name>\",\n# \"Upsert\" : \"true\"\n#}\n\n# Write configuration\nwriteConfig = {\n \"Endpoint\" : \"https://mysqldb.documents.azure.com:443/\",\n \"Masterkey\" : \"ZLLIuOgqdWwORZWP44coCCokCfrJ0bLdrSw2gxz62UYkd3IYgdCO5EvbUoJ4soZ8zH2btRmyaXw57tL1SDSzxg==\",\n \"Database\" : \"samples\",\n \"Collection\" : \"radiosample\",\n \"Upsert\" : \"true\"\n}\n\n# Write to Cosmos DB from the renamedColumnsDF DataFrame\nrenamedColumnsDF.write.format(\"com.microsoft.azure.cosmosdb.spark\").options(**writeConfig).save()"],"metadata":{},"outputs":[],"execution_count":8}],"metadata":{"name":"dbRadio","notebookId":3026874968085684},"nbformat":4,"nbformat_minor":0}
